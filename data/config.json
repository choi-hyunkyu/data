config = {
    "batch_size": 64, 
    "embedding_dim": 64,
    "num_vocab": 0, 
    "num_encoding_vocab": 0,
    "num_decoding_vocab": 0,
    "num_sequence": 64, 
    "num_encoding_sequence": 512,
    "num_decoding_sequence": 512,
    "num_layers": 12,
    "hidden_size": 128,
    "i_pad": 0,
    "d_ff": 3072,
    "num_head": 12,
    "d_head": 64,
    "dropout": 0.1,
    "layer_norm_epsilon": 1e-12,
    "output_size": 2,
    "weight_decay": 0,
    "learning_rate": 5e-5,
    "max_norm": 5,
    "adam_epsilon": 1e-8,
    "warmup_steps": 0,
    "nb_epochs": 100
}
